# Welcome to the LLM Practice Repository

This repository contains a set of practice assignments for Generative AI for Natural Language Processing. Each assignment covers a specific topic in Gen AI for NLP and has an accompanying dataset for analysis when required.

If you are looking for **classical machine learning exercises**, please check out the [aimlpractice](https://github.com/weprintmoney/aimlpractice) repo.

## Table of Contents

- [Generative AI Foundations](#generative-ai-foundations)
- [The Pathway to Generative AI](#the-pathway-to-generative-ai)
- [Text Preprocessing](#text-preprocessing)
- [Introduction to Generative AI and Prompt Engineering](#introduction-to-generative-ai-and-prompt-engineering)
- [Generative AI Solutions for Natural Language Processing](#generative-ai-solutions-for-natural-language-processing)
- [Transformers for Natural Language Processing](#transformers-for-natural-language-processing)
- [How to Use](#how-to-use)

## Generative AI Foundations
**Goals:** Explain the framework and components of a typical modern-day Generative AI solution 

**Skills & Tools Covered:**
- Text Manipulation and Processing
- Model Utilization and Evaluation
- Utilizing OpenAI and YouTube APIs
- ðŸ¤— Hub for model download
- ðŸ¤— and ðŸ¦œðŸ”—Libraries

**Slides & Lectures:**
- [Machine Learning Refresher Slides](https://drive.google.com/file/d/1vDTSa6mDbfJSr_DziWEF3N0-KXSTIgMN/view?usp=drive_link)
- [Machine Learning Refresher Lesson](https://drive.google.com/file/d/1L3KizfrC1TzDEmfl4oK6oRcGtPrdQSCv/view?usp=drive_link)

**Notebooks & Datasets:**
- [Using the OpenAI API and ðŸ¤— for YouTube Transcription, Transcript Summarization & Transcript Quiz Generation](https://github.com/weprintmoney/LLMPractice/blob/main/1.01%20-%20YouTube%20Transcription%20with%20Hugging%20Face%20Pipeline.ipynb)
- [Prompt Engineering w/ Llama 2 for NLP Tasks](https://github.com/weprintmoney/LLMPractice/blob/main/1.03%20-%20Prompt%20Engineering%20with%20Llama2%20CPP.ipynb)
- [ðŸ¦œðŸ”— Document Q&A System](https://github.com/weprintmoney/LLMPractice/blob/main/1.02%20-%20LangChain%20Question%20Answering.ipynb)

## The Pathway to Generative AI
**Goals:** Understand and apply NLP text preprocessing techniques. Develop a hybrid machine learning model that integrates text data with tabular metadata for improved classification accuracy.

**Skills & Tools Covered:**
- Text Preprocessing
- Vectorization
- Ensemble and Stacking Techniques
- Model Evaluation

**Slides & Lectures:**
- [The Pathway to Generative AI Slides](https://drive.google.com/file/d/1FIvndFjPqMGJhrtRGA6VmySUQA36gAzO/view?usp=drive_link)
- [The Pathway to Generative AI Lesson](https://drive.google.com/file/d/1iG7wFcp9QXWRadS8R_EmEaXQdA6_LmJz/view?usp=drive_link)

**Notebooks & Datasets:**
- [Text Preprocessing - Fake News Detector](https://github.com/weprintmoney/LLMPractice/blob/main/2.01%20-%20Fake%20News%20Detector.ipynb)
  - Dataset: [Fake_new_v1_dataset.csv](https://drive.google.com/file/d/1DYcCHi-Ua8ii4fQ80S-Wr5Ja0AEercoX/view?usp=drive_link)

## Text Preprocessing
**Goals:** Utilize vectorization techniques such as Bag of Words (BoW) and TF-IDF, and effectively apply these methods within a ML pipeline for NLP tasks.

**Skills & Tools Covered:**
- Bag of Words
- TF-IDF
- LSTMs
- ML Pipelines

**Slides & Lectures:**
- [Text Preprocessing Slides](https://drive.google.com/file/d/1G9tmHpjI4OobKk7OtzpCZ7bTPgaLo3gL/view?usp=drive_link)
- [Text Preprocessing Lesson Part 1](https://drive.google.com/file/d/1p719r4vR5GLx-F6lwtFEUJCNM-B3fDBN/view?usp=drive_link)
- [Text Preprocessing Lesson Part 2](https://drive.google.com/file/d/17tl5X-QElgyhcX1uE4CyAWyZWYnZHEXR/view?usp=drive_link)
- [Neural Networks Slides](https://drive.google.com/file/d/1PNKaV4QMh-amxOueXrMQz9L0meCdHtSh/view?usp=drive_link)
- [Neural Networks Lesson](https://drive.google.com/file/d/1jLSMDEFKFsZ_XIob-ggwNKB71ZsIkaFR/view?usp=drive_link)

**Notebooks & Datasets:**
- [Embeddings With Word2Vec](https://github.com/weprintmoney/LLMPractice/blob/main/3.01%20Embeddings%20With%20Word2Vec.ipynb)
  - Dataset: [3.2+new_reviews.csv](https://drive.google.com/file/d/1kYBLrhm4w8-hQpHIjDdtupe0ocZfN7Kz/view?usp=drive_link)
- [Twitter Airline Sentiment Analysis](https://github.com/weprintmoney/LLMPractice/blob/main/3.02%20Document%20Modeling%20with%20Gensim.ipynb)
  - Dataset: [Tweets.csv](https://drive.google.com/file/d/1iNOcaDlQHInWLVbj_-EmLN7HXdSMEOTu/view?usp=drive_link)
- [Text Generation Using LSTMs](https://github.com/weprintmoney/LLMPractice/blob/main/3.03%20Text%20Generation%20Using%20LSTMs.ipynb)
  - Dataset: [medium_data.csv](https://drive.google.com/file/d/1ormjHygdwHYWjcRGdMbkll20pUo_UYZV/view?usp=drive_link)
- [Machine Translation Using LSTMs](https://github.com/weprintmoney/LLMPractice/blob/main/3.04%20Machine%20Translation%20Using%20LSTMs.ipynb)
 - Dataset: [fra.txt](https://drive.google.com/file/d/1f23MVIiE50Divs-lIOIUDKbpimnU5phd/view?usp=drive_link)

## Introduction to Generative AI and Prompt Engineering
**Goals:** Design, optimize, and apply prompts effectively to harness the full potential of advanced language models for a variety of tasks.

**Skills & Tools Covered:**
- Prompt Engineering
- Self Consistency
- Tree-of-Thought
- Rephrase and Respond
- Context Vectors (CoVe)
- Llama 2 CPP
- Mistral

**Slides & Lectures:**
- [Prompt Engineering Overview Slides](https://drive.google.com/file/d/11JhNPdShosAwZ0iQzMrFBMxqMxP97yFs/view?usp=drive_link)
- [Prompt Engineering Fundamentals Part 1](https://drive.google.com/file/d/1O2i5QoqWtFer1vTmxudn77sjprO8U45z/view?usp=drive_link)
- [Prompt Engineering Fundamentals Part 2](https://drive.google.com/file/d/1JJgmUf3CVomXe_q4loTPjtuRsBD3L5SI/view?usp=drive_link)

**Notebooks & Datasets:**
- [4.01 Prompt Engineering With Llama2 CPP](https://github.com/weprintmoney/LLMPractice/blob/main/4.01%20Prompt%20Engineering%20With%20Llama2%20CPP.ipynb)
- [4.02 Prompt Engineering Use Cases](https://github.com/weprintmoney/LLMPractice/blob/main/4.02%20Prompt%20Engineering%20Use%20Cases.ipynb)
- [4.03 Self-Consistency and Tree-of-Thought Prompting](https://github.com/weprintmoney/LLMPractice/blob/main/4.03%20Self-Consistency%20and%20Tree-of-Thought%20Prompting.ipynb)
- [4.04 - Rephrase and Repond & CoVe Prompting](https://github.com/weprintmoney/LLMPractice/blob/main/4.04%20-%20Self-Consistency%20and%20Tree-of-Thought%20Prompting.ipynb)

## Generative AI Solutions for Natural Language Processing
**Goals:** Utilize LangChain for building AI-driven chatbots and to understand and implement large multimodal models (LMMs), leveraging diverse datasets ranging from textual content to visual data.

**Skills & Tools Covered:**
- Chatbot Development
- Multimodal Learning

**Slides & Lectures:**

**Notebooks & Datasets:**
- [LangChain Essentials](https://github.com/weprintmoney/LLMPractice/blob/main/5.01%20LangChain%20Essentials%20-%20Global%20Warming.ipynb)
  - Dataset: [PDF File - Global Warming](https://drive.google.com/file/d/1h5EdxurntvZ2yRUdhUbe8lMpC9owlp6q/view?usp=drive_link), [HTML File - Global Warming](https://drive.google.com/file/d/1EGsQjZUSakFTXk0QSlc6rGEBVWDGAjGW/view?usp=drive_link), [TXT File - Global Warming](https://drive.google.com/file/d/15PKrQR1g2wBdXbcYYxG74NudQLjuGqUU/view?usp=drive_link) 
- [5.02 LangChain Agent Chatbot Prototype](https://github.com/weprintmoney/LLMPractice/blob/main/5.02%20LangChain%20Agent%20Chatbot%20Prototype.ipynb)
- [5.03 LMMs Large Multimodal Models](https://github.com/weprintmoney/LLMPractice/blob/main/5.03%20LMMs%20Large%20Multimodal%20Models.ipynb)
  - Dataset: [oat_drink.png](https://drive.google.com/file/d/1ZYgwMK4vQDMDQlSZ7cTOmxqVcD_-NJet/view?usp=drive_link), [milk_shelf.png](https://drive.google.com/file/d/122yf8vmEyjfHTnAVODihGq7OT6ZrPToG/view?usp=drive_link)

## Transformers for Natural Language Processing
**Goals:**
- **Understand Sequential Deep Learning:** Gain a comprehensive understanding of deep learning models designed for sequential data, such as recurrent neural networks (RNNs), long short-term memory networks (LSTMs), and gated recurrent units (GRUs).
- **Master Transformer Models:** Acquire knowledge about Transformer models, a revolutionary architecture for sequence processing, widely used in natural language processing (NLP) tasks.
- **Grasp Attention Mechanisms:** Understand the concept of attention mechanisms, which allow models to focus on specific parts of input sequences when making predictions.
- **Explore Popular Transformer Architectures:** Familiarize yourself with popular Transformer architectures such as BERT, GPT (Generative Pre-trained Transformer), and T5 (Text-To-Text Transfer Transformer).

**Skills & Tools Covered:**
- ðŸ¤—Transformers Library
- Tools

**Slides & Lectures:**
- [Transformers Slides](https://drive.google.com/file/d/1bMoQdL54ffqH35_7_VNoA8TOIX-bU_va/view?usp=drive_link)
- [Transformers Lesson](https://drive.google.com/file/d/1UZcAgMCFZFu1A2j0Yue6s929--5nBwL-/view?usp=drive_link)
- [Fine Tuning Lesson](https://drive.google.com/file/d/1jc_LCDpC5QUDffZ-xKFpDSLUasXOy5Xy/view?usp=drive_link)

**Notebooks & Datasets:**
- [Transformer Based LLM Use Cases](https://github.com/weprintmoney/LLMPractice/blob/main/8.03%20-%20Transformer-based%20LLM%20Use%20Cases.ipynb)
- [Sarcasm Detection with Transformers](https://github.com/weprintmoney/LLMPractice/blob/main/8.04%20-%20Sarcasm%20Detection%20with%20Transformers.ipynb)
- [Building the Transformer in Pytorch](https://github.com/weprintmoney/LLMPractice/blob/main/8.12%20-%20Building%20the%20Transformer%20in%20PyTorch.ipynb)
- [Self-Attention](https://github.com/weprintmoney/LLMPractice/blob/main/8.14%20-%20Self-Attention.ipynb)
- [Fine Tuning](https://github.com/weprintmoney/LLMPractice/blob/main/8.20%20-%20Fine%20Tuning.ipynb)
- [Semantic Search with Transformer Embeddings](https://github.com/weprintmoney/LLMPractice/blob/main/9.0%20Semantic%20Search%20with%20Transformer%20Embeddings.ipynb)

## Generative AI Applications with LangChain
**Goals:**
- **Goal 1:** Description

**Skills & Tools Covered:**
- x

**Slides & Lectures:**
- x

**Notebooks & Datasets:**
- x

## How to Use

To use the datasets in this repository, please follow the steps below:

1. Copy the dataset to your own Google Drive account by clicking on the dataset link in the assignment description above.
2. Open the dataset in your Google Drive account and click on the "Add shortcut to Drive" button in the upper right corner.
3. In the popup window, select the folder in your Google Drive where you want to add the dataset shortcut, and then click on the "Add shortcut" button.
4. In your local machine or Google Colab notebook, mount your Google Drive using the following code:

```python
from google.colab import drive
drive.mount('/content/drive')
```

5. Access the dataset using the file path of the dataset shortcut in your Google Drive, like this:

```python
import pandas as pd
df = pd.read_csv('/content/drive/My Drive/<folder>/<dataset>')
```

Replace `<folder>` with the name of the folder where you added the dataset shortcut in step 3, and `<dataset>` with the name of the dataset file.

Thank you for checking out my repository. I hope that these assignments will help you gain more knowledge and expertise in AI/ML. If you have any suggestions or feedback, please feel free to contribute or contact me.
