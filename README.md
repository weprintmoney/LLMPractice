# Welcome to the LLM Practice Repository

This repository contains a set of practice assignments for Generative AI for Natural Language Processing. Each assignment covers a specific topic in Gen AI for NLP and has an accompanying dataset for analysis when required.

If you are looking for **classical machine learning exercises**, please check out the [aimlpractice](https://github.com/weprintmoney/aimlpractice) repo.

## Table of Contents

- [Generative AI Foundations](#generative-ai-foundations)
- [The Pathway to Generative AI](#the-pathway-to-generative-ai)
- [Text Preprocessing](#text-preprocessing)
- [Introduction to Generative AI and Prompt Engineering](#introduction-to-generative-ai-and-prompt-engineering)
- [Generative AI Solutions for Natural Language Processing](#generative-ai-solutions-for-natural-language-processing)
- [Transformers for Natural Language Processing](#transformers-for-natural-language-processing)
- [How to Use](#how-to-use)

## Generative AI Foundations
**Goals:** Explain the framework and components of a typical modern-day Generative AI solution 

**Skills & Tools Covered:**
- Text Manipulation and Processing
- Model Utilization and Evaluation
- Utilizing OpenAI and YouTube APIs
- ðŸ¤— Hub for model download
- ðŸ¤— and ðŸ¦œðŸ”—Libraries

**Notebooks & Datasets:**
- [Using the OpenAI API and ðŸ¤— for YouTube Transcription, Transcript Summarization & Transcript Quiz Generation](https://github.com/weprintmoney/LLMPractice/blob/main/1.01%20-%20YouTube%20Transcription%20with%20Hugging%20Face%20Pipeline.ipynb)
- [Prompt Engineering w/ Llama 2 for NLP Tasks](https://github.com/weprintmoney/LLMPractice/blob/main/1.03%20-%20Prompt%20Engineering%20with%20Llama2%20CPP.ipynb)
- [ðŸ¦œðŸ”— Document Q&A System](https://github.com/weprintmoney/LLMPractice/blob/main/1.02%20-%20LangChain%20Question%20Answering.ipynb)

## The Pathway to Generative AI
**Goals:** Understand and apply NLP text preprocessing techniques. Develop a hybrid machine learning model that integrates text data with tabular metadata for improved classification accuracy.

**Skills & Tools Covered:**
- Text Preprocessing
- Vectorization
- Ensemble and Stacking Techniques
- Model Evaluation

**Notebooks & Datasets:**
- [Text Preprocessing - Fake News Detector](https://github.com/weprintmoney/LLMPractice/blob/main/2.01%20-%20Fake%20News%20Detector.ipynb)
  - Dataset: [Fake_new_v1_dataset.csv](https://drive.google.com/file/d/1DYcCHi-Ua8ii4fQ80S-Wr5Ja0AEercoX/view?usp=drive_link)

## Text Preprocessing
**Goals:** Utilize vectorization techniques such as Bag of Words (BoW) and TF-IDF, and effectively apply these methods within a ML pipeline for NLP tasks.

**Skills & Tools Covered:**
- Bag of Words
- TF-IDF
- LSTMs
- ML Pipelines

**Notebooks & Datasets:**
- [Embeddings With Word2Vec](https://github.com/weprintmoney/LLMPractice/blob/main/3.01%20Embeddings%20With%20Word2Vec.ipynb)
  - Dataset: [3.2+new_reviews.csv](https://drive.google.com/file/d/1kYBLrhm4w8-hQpHIjDdtupe0ocZfN7Kz/view?usp=drive_link)
- [Twitter Airline Sentiment Analysis](https://github.com/weprintmoney/LLMPractice/blob/main/3.02%20Document%20Modeling%20with%20Gensim.ipynb)
  - Dataset: [Tweets.csv](https://drive.google.com/file/d/1iNOcaDlQHInWLVbj_-EmLN7HXdSMEOTu/view?usp=drive_link)
- [Text Generation Using LSTMs](https://github.com/weprintmoney/LLMPractice/blob/main/3.03%20Text%20Generation%20Using%20LSTMs.ipynb)
  - Dataset: [medium_data.csv](https://drive.google.com/file/d/1ormjHygdwHYWjcRGdMbkll20pUo_UYZV/view?usp=drive_link)
- [Machine Translation Using LSTMs](https://github.com/weprintmoney/LLMPractice/blob/main/3.04%20Machine%20Translation%20Using%20LSTMs.ipynb)
 - Dataset: [fra.txt](https://drive.google.com/file/d/1f23MVIiE50Divs-lIOIUDKbpimnU5phd/view?usp=drive_link)

## Introduction to Generative AI and Prompt Engineering
**Goals:** Design, optimize, and apply prompts effectively to harness the full potential of advanced language models for a variety of tasks.

**Skills & Tools Covered:**
- Prompt Engineering
- Self Consistency
- Tree-of-Thought
- Rephrase and Respond
- Context Vectors (CoVe)
- Llama 2 CPP
- Mistral

**Notebooks & Datasets:**
- [4.01 Prompt Engineering With Llama2 CPP](https://github.com/weprintmoney/LLMPractice/blob/main/4.01%20Prompt%20Engineering%20With%20Llama2%20CPP.ipynb)
- [4.02 Prompt Engineering Use Cases](https://github.com/weprintmoney/LLMPractice/blob/main/4.02%20Prompt%20Engineering%20Use%20Cases.ipynb)
- [4.03 Self-Consistency and Tree-of-Thought Prompting](https://github.com/weprintmoney/LLMPractice/blob/main/4.03%20Self-Consistency%20and%20Tree-of-Thought%20Prompting.ipynb)
- [4.04 - Rephrase and Repond & CoVe Prompting](https://github.com/weprintmoney/LLMPractice/blob/main/4.04%20-%20Self-Consistency%20and%20Tree-of-Thought%20Prompting.ipynb)

## Generative AI Solutions for Natural Language Processing
**Goals:** Utilize LangChain for building AI-driven chatbots and to understand and implement large multimodal models (LMMs), leveraging diverse datasets ranging from textual content to visual data.

**Skills & Tools Covered:**
- Chatbot Development
- Multimodal Learning

**Notebooks & Datasets:**
- [LangChain Essentials](https://github.com/weprintmoney/LLMPractice/blob/main/5.01%20LangChain%20Essentials%20-%20Global%20Warming.ipynb)
  - Dataset: [PDF File - Global Warming](https://drive.google.com/file/d/1h5EdxurntvZ2yRUdhUbe8lMpC9owlp6q/view?usp=drive_link), [HTML File - Global Warming](https://drive.google.com/file/d/1EGsQjZUSakFTXk0QSlc6rGEBVWDGAjGW/view?usp=drive_link), [TXT File - Global Warming](https://drive.google.com/file/d/15PKrQR1g2wBdXbcYYxG74NudQLjuGqUU/view?usp=drive_link) 
- [5.02 LangChain Agent Chatbot Prototype](https://github.com/weprintmoney/LLMPractice/blob/main/5.02%20LangChain%20Agent%20Chatbot%20Prototype.ipynb)
- [5.03 LMMs Large Multimodal Models](https://github.com/weprintmoney/LLMPractice/blob/main/5.03%20LMMs%20Large%20Multimodal%20Models.ipynb)
  - Dataset: [oat_drink.png](https://drive.google.com/file/d/1ZYgwMK4vQDMDQlSZ7cTOmxqVcD_-NJet/view?usp=drive_link), [milk_shelf.png](https://drive.google.com/file/d/122yf8vmEyjfHTnAVODihGq7OT6ZrPToG/view?usp=drive_link)

## Transformers for Natural Language Processing
**Goals:**
- **Understand Sequential Deep Learning:** Gain a comprehensive understanding of deep learning models designed for sequential data, such as recurrent neural networks (RNNs), long short-term memory networks (LSTMs), and gated recurrent units (GRUs).
- **Master Transformer Models:** Acquire knowledge about Transformer models, a revolutionary architecture for sequence processing, widely used in natural language processing (NLP) tasks.
- **Grasp Attention Mechanisms:** Understand the concept of attention mechanisms, which allow models to focus on specific parts of input sequences when making predictions.
- **Explore Popular Transformer Architectures:** Familiarize yourself with popular Transformer architectures such as BERT, GPT (Generative Pre-trained Transformer), and T5 (Text-To-Text Transfer Transformer).

**Skills & Tools Covered:**
- ðŸ¤—Transformers Library

**Notebooks & Datasets:**
- [Transformer Based LLM Use Cases](https://github.com/weprintmoney/LLMPractice/blob/main/8.03%20-%20Transformer-based%20LLM%20Use%20Cases.ipynb)
- [Sarcasm Detection with Transformers](https://github.com/weprintmoney/LLMPractice/blob/main/8.04%20-%20Sarcasm%20Detection%20with%20Transformers.ipynb)
- [Building the Transformer in Pytorch](https://github.com/weprintmoney/LLMPractice/blob/main/8.12%20-%20Building%20the%20Transformer%20in%20PyTorch.ipynb)
- [Self-Attention](https://github.com/weprintmoney/LLMPractice/blob/main/8.14%20-%20Self-Attention.ipynb)
- [Fine Tuning](https://github.com/weprintmoney/LLMPractice/blob/main/8.20%20-%20Fine%20Tuning.ipynb)
- [Semantic Search with Transformer Embeddings](https://github.com/weprintmoney/LLMPractice/blob/main/9.0%20Semantic%20Search%20with%20Transformer%20Embeddings.ipynb)

## Generative AI Applications with LangChain
**Goals:**
- **Working With LangChain Agents:** Gain an understanding of the process involved in creating LangChain Pandas DataFrame agents, and how these are utilized in creating applications such as Data Science Assistants
- **Fine tuning with QLoRA:** Obtain an insight into Fine-tuning Open-Source LLMs by using QLoRA (Quantized Low-rank Adaptation) on the Llama 2 7B chat model

**Skills & Tools Covered:**
- Integration of techniques such as NLP for database querying and RAG for contextual question answering
- Leveraging external resources like the OpenAI API to enhance project capabilities
- Identifying potential biases, privacy considerations, and implications for diverse stakeholders
- Mitigating risks and upholding ethical principles

**Notebooks & Datasets:**
- [Developing AI Assistants with LangChain](https://github.com/weprintmoney/LLMPractice/blob/main/10.10%20-%20Developing%20AI%20Assistants%20with%20LangChain.ipynb)
  - [Dataset: Pima Indians Diabetes]()
- [Fine-tuning Llama 2 for Dialog Summarization with QLoRA](https://github.com/weprintmoney/LLMPractice/blob/main/10.20%20-%20Fine-tuning%20Llama%202%20for%20Dialog%20Summarization%20with%20QLoRA)
- [LangChain Data Science Assistant](https://github.com/weprintmoney/LLMPractice/blob/main/10.20%20-%20LangChain%20Data%20Science%20Assistant.ipynb)

For more **fun with LangChain**, please check out the [Austin LangChain Group](https://github.com/colinmcnamara/austin_langchain/tree/main/labs) repo.

## How to Use

To use the datasets in this repository, please follow the steps below:

1. Copy the dataset to your own Google Drive account by clicking on the dataset link in the assignment description above.
2. Open the dataset in your Google Drive account and click on the "Add shortcut to Drive" button in the upper right corner.
3. In the popup window, select the folder in your Google Drive where you want to add the dataset shortcut, and then click on the "Add shortcut" button.
4. In your local machine or Google Colab notebook, mount your Google Drive using the following code:

```python
from google.colab import drive
drive.mount('/content/drive')
```

5. Access the dataset using the file path of the dataset shortcut in your Google Drive, like this:

```python
import pandas as pd
df = pd.read_csv('/content/drive/My Drive/<folder>/<dataset>')
```

Replace `<folder>` with the name of the folder where you added the dataset shortcut in step 3, and `<dataset>` with the name of the dataset file.

Thank you for checking out my repository. I hope that these assignments will help you gain more knowledge and expertise in AI/ML. If you have any suggestions or feedback, please feel free to contribute or contact me.
